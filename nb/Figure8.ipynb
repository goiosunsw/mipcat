{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a91c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import ma\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import scipy.signal as sig\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from pykalman import KalmanFilter\n",
    "from timeseries import SampledTimeSeries\n",
    "from mipcat.signal.timeseries_generator import ts_from_pickle\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7a5f9",
   "metadata": {},
   "source": [
    "# Folder with dataset\n",
    "\n",
    "Change this to the folder where the downloaded dataset (`mozart_sample.zip`) was extracted and the folder where calculated timeseries reside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db999b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = \"/mipcat/data/original/\"\n",
    "calcroot = \"/mipcat/data/calc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68ed8a6",
   "metadata": {},
   "source": [
    "# Read segmentation\n",
    "\n",
    "`mozart_notes.csv` contains a compilation of the segmentations for all the recordings in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808562e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "notedf = pd.read_csv(os.path.join(calcroot,\"mozart_notes.csv\"),index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6772717",
   "metadata": {},
   "source": [
    "# Add metadata\n",
    "\n",
    "Extract some needed information, some contained in the filenames, other from the music sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bd4e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#notedf = notedf[notedf['clip'].isin(['1', '2', 'mozart (0)'])]\n",
    "\n",
    "# Convert windows paths to unix paths\n",
    "notedf[\"text_grid\"]=notedf.text_grid.str.replace(\"\\\\\",\"/\",regex=False)\n",
    "\n",
    "# Note index is contained in the segmentation label\n",
    "# This corresponds to the order number of the note in the music sheet\n",
    "notedf['note_idx'] = notedf.label.str.extract('^([0-9]+).*').astype('int')\n",
    "\n",
    "# Generate a unique index number for each version played\n",
    "notedf['gl_ver_idx'] = notedf.groupby(['text_grid','clip'])[['text_grid','clip']].ngroup()\n",
    "\n",
    "# Gather the subject number from the filename\n",
    "notedf['subj_id'] = notedf.text_grid.apply(lambda x: x.split('/')[-3])\n",
    "\n",
    "# Gather some more information from the file path\n",
    "subdirs = notedf.text_grid.apply(lambda x: x.split('/')[-2])\n",
    "notedf['instrument'] = 'lab'\n",
    "notedf.loc[notedf.text_grid.str.contains('Own'),'instrument']='own'\n",
    "\n",
    "notedf[\"sigfile\"]=notedf.text_grid.str.replace(\"_notes.TextGrid\",\"_ts.pickle\",regex=False)\n",
    "#notedf[\"duration\"]=notedf.end-notedf.start\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b911fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataroot+\"melodies.yaml\") as f:\n",
    "    meljs = yaml.safe_load(f)\n",
    "    \n",
    "tunejs = meljs['mozart']\n",
    "tunedf = pd.DataFrame(tunejs['notes'])\n",
    "tune_bar = tunejs['bar_duration']\n",
    "\n",
    "b = 0\n",
    "for ii, n in tunedf.iterrows():\n",
    "    if n.strong_beat==True:\n",
    "        b=0\n",
    "    if b%tune_bar==0:\n",
    "        tunedf.loc[ii,'strong_beat'] = True\n",
    "    b+=n.duration\n",
    "    \n",
    "tunedf['start_beat']=tunedf.shift().duration.cumsum().fillna(0)\n",
    "tunedf = tunedf[tunedf.pitch!=0].reset_index()\n",
    "#tunedf.loc[tunedf.pitch!=0,'note_idx'] = np.arange(sum(tunedf.pitch!=0))\n",
    "\n",
    "ndf = notedf.join(tunedf,on='note_idx',how='left')\n",
    "\n",
    "# get name of original wav file\n",
    "# needed to get video file\n",
    "wavdf = pd.read_csv(dataroot+'/wav_list.csv',index_col=0)\n",
    "wm=ndf.text_grid.apply(lambda x:pd.Series([x.find(os.path.splitext(y)[0]) for y in wavdf.filename],index=wavdf.filename))\n",
    "ndf['wavfile']=wm.idxmax(axis=1)\n",
    "ndf[(wm<0).all(axis=1)] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f2d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.groupby('gl_ver_idx').apply(lambda x: x[['subj_id','instrument']].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567de62a",
   "metadata": {},
   "source": [
    "# Read video information\n",
    "\n",
    "The following file contains information such as video delay relative to main signal file, and clainet marker IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d97e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "videodf = pd.read_csv(dataroot+'/wav_video_delays.csv')\n",
    "videodf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e455f2",
   "metadata": {},
   "source": [
    "# Choose trials to compare\n",
    "\n",
    "Write the global version numbers next (`gl_ver_idx` column in the notedf table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cadbe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = [1,2,4,5];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c1781b",
   "metadata": {},
   "source": [
    "# Parse clarinet marker file\n",
    "\n",
    "Reads the marker file and chooses the relevant markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1932daee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_aruco(data):\n",
    "    times = np.zeros(len(data))\n",
    "    aruco_ids = np.array(list(set([int(x) for y in data for x in y  if re.match(r'^[0-9]+$',x)])))\n",
    "    id_max = len(aruco_ids)\n",
    "\n",
    "    aruco_arr = np.ones((len(data),len(aruco_ids),2))*np.nan\n",
    "    aruco_dim = np.ones((len(data),len(aruco_ids),2))*np.nan\n",
    "\n",
    "    for fno, ad in enumerate(data):\n",
    "        times[fno] = ad['msec']/1000\n",
    "        for ii, aid in enumerate(aruco_ids):\n",
    "            try:\n",
    "                val = ad[str(aid)]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            rect = val['bbox']\n",
    "            y = -(rect[1]+rect[3]/2)\n",
    "            x = (rect[0]+rect[2]/2)\n",
    "            aruco_dim[fno, ii, :] = [rect[2],rect[3]]\n",
    "            aruco_arr[fno, ii, :] = [x,y]\n",
    "        times[fno] = ad['msec'] / 1000\n",
    "        \n",
    "    return aruco_ids, times, aruco_arr, aruco_dim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5c578",
   "metadata": {},
   "source": [
    "# Kalman filtering\n",
    "\n",
    "Custom Kalman filter for 2D motion that tries to remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f54f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfilter(x, observation_error=0.05, observation_cov=0.001,\n",
    "               pos_proc_error=0.15, pos_proc_xy_cov=0.015,\n",
    "               vel_proc_error=0.25, vel_proc_xy_cov=0.05,\n",
    "               pos_vel_proc_xx_cov=0.1, pos_vel_proc_xy_cov=0.025,\n",
    "               outl_cov_fact=100000, outl_pos_thresh=50):\n",
    "    \"\"\"\n",
    "    Use Kalman to filter a XY position sequence.\n",
    "    \n",
    "    observation_error and observation_cov is the estimated error/cov of the measured position\n",
    "    the 6 _proc_error and _proc_cov are coefficients for the covariance matrix of the model \n",
    "    (model is x_ij+1 = x_ij+v_ij*t)\n",
    "    outl_cov_fact is a factor applied to process (model) transition matrix. Matrix is divided by this factor,\n",
    "    making for a more aggressive filtering\n",
    "    Outliers that move further than outl_pos_thresh of the filtered model are treated as missing observations\n",
    "    \"\"\"\n",
    "    preds = np.zeros(x.shape)\n",
    "    for ii in range(x.shape[1]):\n",
    "        # Find nan values \n",
    "        meas = ma.array(x[:,ii,:].copy())\n",
    "        naidx = np.flatnonzero(np.isnan(meas[:,0]))\n",
    "        ndiff = np.diff(naidx)\n",
    "\n",
    "        # Calculate initial state estimate based on non-nan values\n",
    "        if len(ndiff)>0 and np.max(ndiff)>1:\n",
    "            amax = np.argmax(ndiff)\n",
    "            naidx[amax]\n",
    "            mfit = meas[naidx[amax]+1:naidx[amax+1]-1]\n",
    "        else:\n",
    "            mfit = meas[~np.isnan(meas[:,0]),:]\n",
    "        kf = KalmanFilter(initial_state_mean=np.concatenate((np.nanmean(mfit,axis=0),[0,0])),\n",
    "                                                            n_dim_obs=2,n_dim_state=4)\n",
    "\n",
    "        ### Aggressive filtering to detect outliers\n",
    "        # transition matrices\n",
    "        kf.transition_matrices = np.array([[1,0,1,0],[0,1,0,1],\n",
    "                                           [0,0,1,0],[0,0,0,1]])\n",
    "\n",
    "        # mask nan-values\n",
    "        meas[np.isnan(meas)]=ma.masked\n",
    "\n",
    "        kf.observation_covariance = np.array([[observation_error, observation_cov],\n",
    "                                              [observation_cov, observation_error]])\n",
    "\n",
    "        kf.transition_covariance = np.array([[pos_proc_error, pos_proc_xy_cov, pos_vel_proc_xx_cov, pos_vel_proc_xy_cov],\n",
    "                                             [pos_proc_xy_cov, pos_proc_error, pos_vel_proc_xy_cov, pos_vel_proc_xx_cov],\n",
    "                                             [pos_vel_proc_xx_cov, pos_vel_proc_xy_cov, vel_proc_error, vel_proc_xy_cov],\n",
    "                                             [pos_vel_proc_xy_cov, pos_vel_proc_xx_cov, vel_proc_xy_cov, vel_proc_error]])/outl_cov_fact\n",
    "        #pred_m,pred_cov=kf.em(mfit).smooth(meas)\n",
    "        pred_m,pred_cov=kf.smooth(meas)\n",
    "        pred_r = pred_m\n",
    "\n",
    "        # Remove outliers from final filtering\n",
    "        outl = np.sqrt(np.sum((meas-pred_m[:,:2])**2,axis=1))>outl_pos_thresh\n",
    "        print(f\"Outliers: {np.sum(outl)}/{len(outl)}\")\n",
    "\n",
    "        meas[outl,:]=ma.masked\n",
    "\n",
    "        ### Final filtering \n",
    "        kf = KalmanFilter(initial_state_mean=np.concatenate((np.nanmean(mfit,axis=0),[0,0])),\n",
    "                                                            n_dim_obs=2,n_dim_state=4)\n",
    "        kf.transition_matrices = np.array([[1,0,1,0],[0,1,0,1],\n",
    "                                           [0,0,1,0],[0,0,0,1]])\n",
    "\n",
    "        kf.observation_covariance = np.array([[observation_error, observation_cov],\n",
    "                                              [observation_cov, observation_error]])\n",
    "\n",
    "        kf.transition_covariance = np.array([[pos_proc_error, pos_proc_xy_cov, pos_vel_proc_xx_cov, pos_vel_proc_xy_cov],\n",
    "                                             [pos_proc_xy_cov, pos_proc_error, pos_vel_proc_xy_cov, pos_vel_proc_xx_cov],\n",
    "                                             [pos_vel_proc_xx_cov, pos_vel_proc_xy_cov, vel_proc_error, vel_proc_xy_cov],\n",
    "                                             [pos_vel_proc_xy_cov, pos_vel_proc_xx_cov, vel_proc_xy_cov, vel_proc_error]])\n",
    "\n",
    "        pred_m,pred_cov=kf.smooth(meas)\n",
    "    \n",
    "        preds[:,ii,:] = pred_m[:,:2]\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e638ee6",
   "metadata": {},
   "source": [
    "Helper function to subtract two time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ca3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_diff(ts1,ts2):\n",
    "    t0 = max(ts1.t_start, ts2.t_start)\n",
    "    te = min(ts1.t[-1],ts2.t[-1])\n",
    "    t1,v1 = ts1.times_values_in_range(from_time=t0,to_time=te)\n",
    "    t2,v2 = ts2.times_values_in_range(from_time=t0,to_time=te)\n",
    "    return SampledTimeSeries(t=t1, v=np.interp(t1,t2,v2)-v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef36953",
   "metadata": {},
   "source": [
    "Helper function to calculate orientation of a line segment between two ponts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb603020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_angle(p1, p2):\n",
    "    return 180/np.pi*np.arctan((p2[...,1]-p1[...,1])/(p2[...,0]-p1[...,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae1458",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "marg = 5\n",
    "nmark=33\n",
    "coords = ['x','y','z']\n",
    "\n",
    "rec_dict = [{'wavfile': x} for x in ndf[ndf.gl_ver_idx.isin(trials)].wavfile.unique()]\n",
    "\n",
    "for md in rec_dict:\n",
    "    \n",
    "    sigfile = md['wavfile']\n",
    "    tsfile = ndf[ndf.wavfile==sigfile].sigfile.iloc[0]\n",
    "    relpath = os.path.split(sigfile)[0]\n",
    "    print(sigfile)\n",
    "    \n",
    "    # store needed time series for plot\n",
    "    sr, w = sio.wavfile.read(os.path.join(dataroot,sigfile))\n",
    "    tsl = ts_from_pickle(os.path.join(calcroot,tsfile))\n",
    "\n",
    "    md['wav'] = w\n",
    "    md['sr'] = sr\n",
    "    \n",
    "    try:\n",
    "        md['f0'] = [ts for ts in tsl if ts.label==\"barrel_f0\"][0]\n",
    "    except IndexError:\n",
    "        md['f0'] = [ts for ts in tsl if ts.label==\"external_f0\"][0]\n",
    "    md['ampl'] = [ts for ts in tsl if ts.label==\"external_ampl\"][0]\n",
    "    try:\n",
    "        md['mouth_dc'] = [ts for ts in tsl if ts.label==\"mouth_dc\"][0]\n",
    "        md['reed_dc'] = [ts for ts in tsl if ts.label==\"reed_dc\"][0]\n",
    "    except IndexError:\n",
    "        print(\"No musician parameter\")\n",
    "    \n",
    "    df = ndf[ndf.sigfile==tsfile]\n",
    "    print(df.gl_ver_idx.unique())\n",
    "    md['notes'] = df\n",
    "    md['versions'] = df.gl_ver_idx.unique()\n",
    "\n",
    "    \n",
    "    # gather clarinet video data (front and side views)\n",
    "    for view in ['front','side']:\n",
    "        video_file_cell = videodf.loc[(videodf['Video file'].str.lower().str.match(f'.*{view}'))&\n",
    "                                (videodf['Signal file']==sigfile),'Video file']\n",
    "        video_file = video_file_cell.iloc[0]\n",
    "        marker_file = os.path.splitext(video_file.strip())[0]+'.json'\n",
    "        print(marker_file)\n",
    "        with open(dataroot+'/'+relpath+'/'+marker_file,'r') as f:\n",
    "            data=json.load(f)\n",
    "            \n",
    "        delay = videodf.loc[video_file_cell.index, 'Video to signal delay'].values[0]\n",
    "        \n",
    "        # rotate marker coordinates if needed\n",
    "        ang = float(videodf.loc[video_file_cell.index,'Rotate'])/180*np.pi\n",
    "        rot_mx=np.array([[np.cos(ang),np.sin(ang)],[-np.sin(ang),np.cos(ang)]])\n",
    "        ids, time, vals, dims = parse_aruco(data)\n",
    "        vals_rot = rot_mx.dot(vals.transpose((0,2,1))).transpose((1,2,0))\n",
    "        \n",
    "        # Select only interesting markers\n",
    "        idnbrs = videodf.loc[video_file_cell.index, videodf.columns[videodf.columns.str.contains('marker')]].values[0]\n",
    "        idi = np.asarray([np.where(ids==idnbr)[0][0] for idnbr in idnbrs])\n",
    "        vals = vals_rot[:,idi,:]\n",
    "\n",
    "        # select region of interest\n",
    "        tmax = np.max(md['ampl'].t)\n",
    "        idx = (time>-delay-marg)&(time<tmax-delay+marg)\n",
    "        time = time[idx]\n",
    "        vals = vals[idx]\n",
    "\n",
    "        # Kalman filter fills in undetected markers in certain frames\n",
    "        vals = kfilter(vals)\n",
    "        print(vals.shape)\n",
    "\n",
    "        # calculate clarinet angle\n",
    "        cdiff = np.diff(vals,axis=1)[:,0,:]\n",
    "        ang = -np.arctan(cdiff[:,0]/cdiff[:,1])/np.pi*180\n",
    "        leng = np.sqrt(np.sum(cdiff**2,axis=1))\n",
    "        \n",
    "        # subtract video delay and generate timeseries\n",
    "        time += delay\n",
    "        md[f'{view}_angle']=SampledTimeSeries(t=time, v=ang)\n",
    "        \n",
    "        # POSE data\n",
    "        try:            \n",
    "            pose_file = os.path.splitext(video_file.strip())[0]+'_Pose.pickle'\n",
    "\n",
    "            with open(dataroot+'/'+relpath+'/'+pose_file,'rb') as f:\n",
    "                data=pickle.load(f)\n",
    "             \n",
    "            pose_angles = np.ones((len(data),5))*np.nan\n",
    "            times = np.zeros(len(data))\n",
    "\n",
    "            rad_to_deg = 180/np.pi\n",
    "            \n",
    "            # Markers to tensor\n",
    "            vals = np.ones((len(data),nmark,len(coords)))*np.nan\n",
    "            times = np.ones((len(data)))*np.nan\n",
    "            for ti in range(len(data)):\n",
    "                times[ti] = data[ti]['time']\n",
    "                if 'landmarks' in data[ti]:\n",
    "                    for ii in data[ti]['landmarks']:\n",
    "                        for jj,coord in enumerate(coords):\n",
    "                            try:\n",
    "                                vals[ti,ii,jj] = data[ti]['landmarks'][ii][coord]\n",
    "                            except IndexError:\n",
    "                                pass\n",
    "                            \n",
    "            idx = (times>-delay-marg)&(times<tmax-delay+marg)\n",
    "            # filter markers (only x-y coords)\n",
    "            midx = np.array([6,8])\n",
    "            fvals = kfilter(vals[idx,:,:2][:,midx,:],observation_error=15)\n",
    "\n",
    "               \n",
    "            #pose_angles = pose_angles[idx,:]\n",
    "            times += delay\n",
    "            md['head_angle'] = SampledTimeSeries(t=times[idx], v=calc_angle(fvals[:,0,:],fvals[:,1,:]))\n",
    "            #md['mouth_hand_angle'] = SampledTimeSeries(t=times[idx], v=fvals[idx,4])\n",
    "            #md['torso_angle'] = SampledTimeSeries(t=times[idx], v=pose_angles[idx,3])\n",
    "        except IOError:\n",
    "            print('Pose data note found')\n",
    "    try:\n",
    "        # gather mouthpiece video data \n",
    "        video_file_cell = videodf.loc[(videodf['Video file'].str.lower().str.match(f'.*mouthpiece'))&\n",
    "                                (videodf['Signal file']==sigfile),'Video file']\n",
    "        video_file = video_file_cell.iloc[0]\n",
    "        marker_file = os.path.splitext(video_file.strip())[0]+'.json'\n",
    "        print(marker_file)\n",
    "\n",
    "        with open(dataroot+'/'+relpath+'/'+marker_file,'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        time = np.array([x['time'] for x in data])\n",
    "        vals = np.array([x['area'] for x in data])\n",
    "        plt.figure()\n",
    "        plt.plot(time,vals)\n",
    "        plt.title(marker_file)\n",
    "        plt.axvline(-videodf.loc[video_file_cell.index, 'Video to signal delay'].values[0],color='r')\n",
    "        # subtract video delay and generate timeseries\n",
    "        time += videodf.loc[video_file_cell.index, 'Video to signal delay'].values[0]\n",
    "        \n",
    "        t = np.arange(0,md['ampl'].t[-1],np.median(np.diff(time)))\n",
    "        idx = (time>-5)&(time<md['ampl'].t[-1]+5)\n",
    "        v = np.interp(t,time[idx],vals[idx])\n",
    "        md['lips']=SampledTimeSeries(t=t, v=v)\n",
    "\n",
    "    except IndexError:\n",
    "        print(\"No mouthpiece video data found\")\n",
    "\n",
    "\n",
    "    # Calculate angle from vertical\n",
    "    a1 = md['front_angle']\n",
    "    a2 = md['side_angle']\n",
    "    tmin = max(np.min(a1.t),np.min(a2.t))\n",
    "    tmax = min(np.max(a1.t),np.max(a2.t))\n",
    "    dt = min(a1.dt,a2.dt)\n",
    "    t = np.arange(tmin,tmax,dt)\n",
    "\n",
    "    md['angle'] = SampledTimeSeries(t=t,v=np.sqrt(a1[t]**2+a2[t]**2))\n",
    "    md['cl_head_angle'] = ts_diff(md['side_angle'],md['head_angle']*-1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3998c0c0",
   "metadata": {},
   "source": [
    "# Plot figure 8 for article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5959ce0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tslabels = [k for k,v in rec_dict[0].items() if type(v) is SampledTimeSeries]\n",
    "\n",
    "marg=1\n",
    "labels = {\"f0\":\"Freq. (Hz)\",\n",
    "          \"ampl\":\"RMS Ampl.\\n(Pa)\",\n",
    "          \"mouth_dc\":\"Blowing P.\\n(Pa)\",\n",
    "          \"reed_dc\": \"Reed pos.\\n(norm)\",\n",
    "          \"cl_head_angle\": \"Angle\\n(deg)\",\n",
    "          \"lips\": \"MP covering\\n(Px)\"}\n",
    "fig,ax = plt.subplots(len(labels),sharex=True)\n",
    "\n",
    "for d in rec_dict:\n",
    "    for v in d['versions']:\n",
    "\n",
    "        n = ndf[ndf.gl_ver_idx==v]\n",
    "        \n",
    "        for axi, lab in zip(ax,labels):\n",
    "            tslab = lab\n",
    "            try:\n",
    "                ats = d[tslab]\n",
    "                if tslab in ['reed_dc']:\n",
    "                    vmax = ats.percentile(95)\n",
    "                    vmin = ats.percentile(5)\n",
    "                    ats = (ats-vmin)/(vmax-vmin)\n",
    "                if tslab == 'ampl':\n",
    "                    axi.set_yscale('log')\n",
    "                if tslab == 'f0':\n",
    "                    ats = ats.apply(sig.medfilt)\n",
    "            except KeyError:\n",
    "                axi.plot(0,0)\n",
    "                continue\n",
    "            #ats.apply(np.log10).plot()\n",
    "            axi.set_ylabel(labels[tslab])\n",
    "\n",
    "            tt,vv=ats.times_values_in_range(n.iloc[0].start-marg,n.iloc[0].start)\n",
    "            tb = (tt-n.iloc[0].start).tolist()\n",
    "            vb = vv.tolist()\n",
    "            beats = []\n",
    "\n",
    "            cur_beat=0\n",
    "            for (nidx, note1), (nidx, note2) in zip(n.iterrows(),n.shift(-1).iterrows()):\n",
    "                #plt.axvspan(note.start, note.end,alpha=.3)\n",
    "                #if np.isnan(note2.start):\n",
    "                end_beat = note1.duration+note1.start_beat\n",
    "                if note2.start_beat is not None and end_beat>= note2.start_beat:\n",
    "                    end = note2.start\n",
    "                else:\n",
    "                    end = note1.end\n",
    "                tn, vn = ats.times_values_in_range(note1.start,end)\n",
    "\n",
    "                tb.extend(np.linspace(note1.start_beat,end_beat,len(vn)))\n",
    "                vb.extend(vn)\n",
    "\n",
    "                if note2.start_beat is not None and end_beat < note2.start_beat:\n",
    "                    tn, vn = ats.times_values_in_range(end,note2.start)\n",
    "                    tb.extend(np.linspace(end_beat,note2.start_beat,len(vn)))\n",
    "                    vb.extend(vn)\n",
    "            tn, vn = ats.times_values_in_range(end,end+marg)\n",
    "            tb.extend(tn-end+end_beat)\n",
    "            vb.extend(vn)\n",
    "            axi.plot(tb,(vb))\n",
    "            \n",
    "\n",
    "        print(n.iloc[0].to_dict())\n",
    "        beats.append(cur_beat)\n",
    "\n",
    "\n",
    "\n",
    "for bs,be in zip(n.start_beat, n.start_beat+n.duration):\n",
    "    #print(b)\n",
    "    for axi in ax:\n",
    "        axi.axvline(bs,alpha=.3,color='r')\n",
    "        axi.axvline(be,alpha=.3,color='m')\n",
    "\n",
    "#ax[1].set_yscale('log')\n",
    "#ax[0].set_ylabel('Frequency (Hz)')\n",
    "#ax[1].set_ylabel('Amplitude (mPa)')\n",
    "#ax[2].set_ylabel('Mouth p (Pa)')\n",
    "#ax[3].set_ylabel('Reed (0-1)')\n",
    "\n",
    "ax[-1].set_xlabel('Beat number')\n",
    "ax[0].legend(['Player A (take 1)','Player A (take 2)','Player B (take 1)','Player B (take 2)'],loc='upper left',bbox_to_anchor=(1,1))\n",
    "fig.align_ylabels()\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
